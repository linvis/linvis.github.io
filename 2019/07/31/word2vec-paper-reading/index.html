<!DOCTYPE html>
<html>
  <head><meta name="generator" content="Hexo 3.9.0">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
  <meta name="description" content="Lin&#39;s blog">
  <meta name="keyword" content="hexo-theme, vuejs">
  
  <link rel="shortcut icon" type="image/ico" href="images/avatar.png">
  
  <title>
     word2vec_paper_reading | Linvis Blog 
  </title>
  <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
  <link href="//cdnjs.cloudflare.com/ajax/libs/nprogress/0.2.0/nprogress.min.css" rel="stylesheet">
  <link href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/tomorrow.min.css" rel="stylesheet">
  <link rel="stylesheet" href="/css/style.css"> 
  <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/geopattern/1.2.3/js/geopattern.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/nprogress/0.2.0/nprogress.min.js"></script>
   <script src="/js/qrious.js"></script>   
  
    <!-- MathJax support START -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <!-- MathJax support END -->
  

 
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-169360841-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() {
    dataLayer.push(arguments);
  }
  gtag("js", new Date());
  gtag("config", "UA-169360841-1");
</script>


</head>
<div class="wechat-share">
  <img src="/css/images/logo.png">
</div>

  <body>
    <header class="header fixed-header">
  <div class="header-container">
    <a class="home-link" href="/">
      <div class="logo"></div>
      <span>Linvis Blog</span>
    </a>
    <ul class="right-list">
      
        <li class="list-item">
          
            <a href="/" class="item-link">Home</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/tags/" class="item-link">Tags</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/archives/" class="item-link">Archives</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/project/" class="item-link">Projects</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/about/" class="item-link">About</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/en/" class="item-link">EN</a>
          
        </li>
      
    </ul>
    <div class="menu">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </div>
    <div class="menu-mask">
      <ul class="menu-list">
        
          <li class="menu-item">
            
              <a href="/" class="menu-link">Home</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/tags/" class="menu-link">Tags</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/archives/" class="menu-link">Archives</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/project/" class="menu-link">Projects</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/about/" class="menu-link">About</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/en/" class="menu-link">EN</a>
            
          </li>
        
      </ul>
    </div>
  </div>
</header>

    <div id="article-banner">
  <h2>word2vec_paper_reading</h2>
  <p class="post-date">2019-07-31</p>
  <div class="arrow-down">
    <a href="javascript:;"></a>
  </div>
</div>
<main class="app-body flex-box">
  <!-- Article START -->
  <article class="post-article">
    <section class="markdown-content"><h1 id="Continuous-Bag-of-Word-Model-CBOW"><a href="#Continuous-Bag-of-Word-Model-CBOW" class="headerlink" title="Continuous Bag-of-Word Model(CBOW)"></a>Continuous Bag-of-Word Model(CBOW)</h1><h2 id="One-word"><a href="#One-word" class="headerlink" title="One word"></a>One word</h2><p>the vocabulary size is V , and the hidden layer size is N</p>
<p>CBOW: input is content words, output is target word</p>
<p>First, let’s see an simple model, one input word, one output word.</p>
<p>for example, two words [‘I’, ‘like’], input is ‘I’, output is ‘like’</p>
<p><img src="/images/word2vec-1.png" style="zoom:50%"></p>
<p>here, we use one-hot encode, ${x_1, x_2…x_v}$, form is $[0,1,…0]$(only one 1)</p>
<p>two weight matrix，$W$ and $W’$</p>
<h3 id="Forward-propagation"><a href="#Forward-propagation" class="headerlink" title="Forward propagation"></a>Forward propagation</h3><p>To get hidden layer：</p>
<script type="math/tex; mode=display">
\mathbf{h} = \mathbf{W}^T \mathbf{x}</script><p>$\mathbf h$ is $N * 1$ dimension</p>
<p>then we have a output vertor named $\mathbf W’$</p>
<script type="math/tex; mode=display">
\mathbf u = \mathbf{W'}^T \mathbf h</script><p>$\mathbf u$ is $V * 1$, same as $\mathbf x$</p>
<p>usually, we use softmax to get the probability.</p>
<script type="math/tex; mode=display">
\mathbf y = softmax(\mathbf u)</script><p>and it is vertor form, if we look at each element’s form of vector, we will get:</p>
<script type="math/tex; mode=display">
\mathbf{h} = \mathbf{W}^T \mathbf{x} = \mathbf{W}_{(k,)}^T:= \mathbf v_{w_I}^T</script><p>here, we know x is one-hot, so $x<em>k = 1, x</em>{k’}=0, k’ \neq  k$, and it multiple with $W^T$,</p>
<p>for example:</p>
<p><img src="/images/word2vec-2.png" style="zoom:50%"></p>
<p>and for $\mathbf u$, each element of $\mathbf u$ should be:</p>
<script type="math/tex; mode=display">
u_j = \mathbf {v'_{w_j}}^T\mathbf h</script><p>for y:</p>
<script type="math/tex; mode=display">
p(w_j|w_I) = y_j = softmax(u_j) =\frac{\exp \left(u_{j}\right)}{\sum_{j^{\prime}=1}^{V} \exp \left(u_{j^{\prime}}\right)}</script><h3 id="backward-propagation"><a href="#backward-propagation" class="headerlink" title="backward propagation"></a>backward propagation</h3><h4 id="for-hidden-output-vector"><a href="#for-hidden-output-vector" class="headerlink" title="for hidden-output vector"></a>for hidden-output vector</h4><p>according maximum likelihood estimation, we want</p>
<script type="math/tex; mode=display">
\begin{aligned} \max p\left(w_{O} | w_{I}\right) &=\max y_{j^{*}} \\ &=\max \log y_{j^{*}} \\ &=u_{j^{*}}-\log \sum_{j^{\prime}=1}^{V} \exp \left(u_{j^{\prime}}\right) :=-E \end{aligned}</script><blockquote>
<p>y_true = [0, 1, 0, 0], y_pred = [0.1, 0.80, 0.01, 0.2], here $j^* = 1, y_{j^*}=0.8$,  and we want $\max y_{j*}$</p>
</blockquote>
<p>where $E=-\log p\left(w<em>{O} | w</em>{I}\right)$ is our loss function, and we want mininum it.</p>
<p>let’s get its derivative:</p>
<script type="math/tex; mode=display">
\frac{\partial E}{\partial u_{j}}=y_{j}-t_{j} :=e_{j}</script><p>here because loss is about $j^<em>$, and derivative is about $j$, so we have $t_j = 1 \ when \  j = j^</em>, else \ t_j = 0$</p>
<p>then go on:</p>
<script type="math/tex; mode=display">
\frac{\partial E}{\partial w_{i j}^{\prime}}=\frac{\partial E}{\partial u_{j}} \cdot \frac{\partial u_{j}}{\partial w_{i j}^{\prime}}=e_{j} \cdot h_{i}</script><p>that is good, we can use it in gradient descent</p>
<script type="math/tex; mode=display">
w_{i j}^{'(new)}=w_{i j}^{'(old)}-\eta \cdot e_{j} \cdot h_{i}</script><p>or </p>
<script type="math/tex; mode=display">
\mathbf{v}_{w_{j}}^{'(new)}=\mathbf{v}_{w_{j}}^{'(old)}-\eta \cdot e_{j} \cdot \mathbf{h} \quad \text { for } j=1,2, \cdots, V</script><h4 id="for-input-hidden-vector"><a href="#for-input-hidden-vector" class="headerlink" title="for input-hidden vector"></a>for input-hidden vector</h4><script type="math/tex; mode=display">
\frac{\partial E}{\partial h_{i}}=\sum_{j=1}^{V} \frac{\partial E}{\partial u_{j}} \cdot \frac{\partial u_{j}}{\partial h_{i}}=\sum_{j=1}^{V} e_{j} \cdot w_{i j}^{\prime} :=\mathrm{EH}_{i}</script><script type="math/tex; mode=display">
h_{i}=\sum_{k=1}^{V} x_{k} \cdot w_{k i}</script><script type="math/tex; mode=display">
\frac{\partial E}{\partial w_{k i}}=\frac{\partial E}{\partial h_{i}} \cdot \frac{\partial h_{i}}{\partial w_{k i}}=\mathrm{EH}_{i} \cdot x_{k}</script><script type="math/tex; mode=display">
\frac{\partial E}{\partial \mathbf{W}}=\mathbf{x} \otimes \mathrm{EH}=\mathbf{x E H}^{T}</script><p>for gradient descent</p>
<script type="math/tex; mode=display">
\mathbf{v}_{w_{I}}^{(new)}=\mathbf{v}_{w_{I}}^{(old)}-\eta \cdot \mathbf E \cdot \mathbf{H}^T \quad</script><h2 id="Multi-word-context"><a href="#Multi-word-context" class="headerlink" title="Multi-word context"></a>Multi-word context</h2><p>We use the average</p>
<script type="math/tex; mode=display">
\begin{aligned} \mathbf{h} &=\frac{1}{C} \mathbf{W}^{T}\left(\mathbf{x}_{1}+\mathbf{x}_{2}+\cdots+\mathbf{x}_{C}\right) \\ &=\frac{1}{C}\left(\mathbf{v}_{w_{1}}+\mathbf{v}_{w_{2}}+\cdots+\mathbf{v}_{w_{C}}\right)^{T} \end{aligned}</script><p><img src="/images/word2vec-3.png" style="zoom:50%"></p>
<p>and</p>
<script type="math/tex; mode=display">
\mathbf{v}_{w_{j}}^{\prime \ (new)}=\mathbf{v}_{w_{j}}^{\prime \ (old) }-\eta \cdot e_{j} \cdot \mathbf{h} \quad \text { for } j=1,2, \cdots, V</script><script type="math/tex; mode=display">
\mathbf{v}_{w_{I, c}}^{(new)}=\mathbf{v}_{w_{I,c}}^{(old)}-\frac{1}{C} \cdot\eta \cdot \mathbf E \cdot \mathbf{H}^T \quad</script><h1 id="Skip-Gram-Model"><a href="#Skip-Gram-Model" class="headerlink" title="Skip-Gram Model"></a>Skip-Gram Model</h1><p><img src="/images/word2vec-4.png" style="zoom:50%"></p>
<p>different with CBOW, skip-gram uses one word input and multiple output words.</p>
<p>for example, we have a word with one-hot $[0, 0, 1, 0, 0]$, and have 3 words which is assiociated,</p>
<p>so y will be $[1, 1, 0, 1,0]$</p>
<h2 id="forward-propagation"><a href="#forward-propagation" class="headerlink" title="forward propagation"></a>forward propagation</h2><p>the calculation of input and hidden is same with CBOW.</p>
<script type="math/tex; mode=display">
\mathbf{h}=\mathbf{W}_{(k, \cdot)}^{T} :=\mathbf{v}_{w_{I}}^{T}</script><p>for hidden to output:</p>
<script type="math/tex; mode=display">
p\left(w_{c, j}=w_{O, c} | w_{I}\right)=y_{c, j}=\frac{\exp \left(u_{c, j}\right)}{\sum_{j^{\prime}=1}^{V} \exp \left(u_{j^{\prime}}\right)}</script><script type="math/tex; mode=display">
u_{c, j}=u_{j}=\mathbf{v}_{w_{j}}^{\prime T} \cdot \mathbf{h}, \text { for } c=1,2, \cdots, C</script><blockquote>
<p>Note: in the Figure 3, we see there is C $W’<em>{N*V}$, but actually they are one $W’</em>{N*V}$,</p>
<p>and why so many y? </p>
<p>for example, like what we say before, the y is [1, 1, 0, 1, 0], for 3 words assiociated, and if we divide it to 3 vector, it is [1, 0, 0, 0, 0],  [0, 1, 0, 0, 0],  [0, 0, 0, 1, 0],  </p>
<p>it explains why we have C output in Figure 3, but they have one shared weight.</p>
</blockquote>
<h2 id="backpropagation"><a href="#backpropagation" class="headerlink" title="backpropagation"></a>backpropagation</h2><p>For loss, it changed to </p>
<script type="math/tex; mode=display">
\begin{aligned} E &=-\log p\left(w_{O, 1}, w_{O, 2}, \cdots, w_{O, C} | w_{I}\right) \\ &=-\log \prod_{c=1}^{C} \frac{\exp \left(u_{c, j_{c}^{*}}\right)}{\sum_{j^{\prime}=1}^{V} \exp \left(u_{j^{\prime}}\right)} \\ &=-\sum_{c=1}^{C} u_{j_{c}^{*}}+C \cdot \log \sum_{j^{\prime}=1}^{V} \exp \left(u_{j^{\prime}}\right) \end{aligned}</script><h3 id="For-hidden-output-vector"><a href="#For-hidden-output-vector" class="headerlink" title="For hidden-output vector"></a>For hidden-output vector</h3><p>and  derivative, each word in C</p>
<script type="math/tex; mode=display">
\frac{\partial E}{\partial u_{c, j}}=y_{c, j}-t_{c, j} :=e_{c, j}</script><p>so, sum it:</p>
<script type="math/tex; mode=display">
\mathrm{EI}_{j}=\sum_{c=1}^{C} e_{c, j}</script><script type="math/tex; mode=display">
\frac{\partial E}{\partial w_{i j}^{\prime}}=\sum_{c=1}^{C} \frac{\partial E}{\partial u_{c, j}} \cdot \frac{\partial u_{c, j}}{\partial w_{i j}^{\prime}}=\mathrm{EI}_{j} \cdot h_{i}</script><p>gradient descent</p>
<script type="math/tex; mode=display">
w_{i j}^{'(new)}=w_{i j}^{'(old)}-\eta \cdot EI_{j} \cdot h_{i}</script><p>or </p>
<script type="math/tex; mode=display">
\mathbf{v}_{w_{j}}^{'(new)}=\mathbf{v}_{w_{j}}^{'(old)}-\eta \cdot E_{j} \cdot \mathbf{h} \quad \text { for } j=1,2, \cdots, V</script><h3 id="For-input-hidden-vector"><a href="#For-input-hidden-vector" class="headerlink" title="For input-hidden vector"></a>For input-hidden vector</h3><script type="math/tex; mode=display">
\mathbf{v}_{w_{I}}^{(new)}=\mathbf{v}_{w_{I}}^{(old)}-\eta \cdot \mathbf E \cdot \mathbf{H}^T \quad</script><p>where $\mathbf{EH}$ is an N-dimension vector, each component of which is defined as:</p>
<script type="math/tex; mode=display">
\mathrm{EH}_{i}=\sum_{j=1}^{V} \mathrm{EI}_{j} \cdot w_{i j}^{\prime}</script></section>
    <!-- Tags START -->
    
    <div class="tags">
      <span>Tags:</span>
      
  <a href="/tags#Machine Learning" >
    <span class="tag-code">Machine Learning</span>
  </a>

  <a href="/tags#paper" >
    <span class="tag-code">paper</span>
  </a>

    </div>
    
    <!-- Tags END -->
    <!-- NAV START -->
    
  <div class="nav-container">
    <!-- reverse left and right to put prev and next in a more logic postition -->
    
      <a class="nav-left" href="/2019/07/13/FreeRTOS-schedule/">
        <span class="nav-arrow">← </span>
        
          FreeRTOS-schedule
        
      </a>
    
    
      <a class="nav-right" href="/2019/12/30/Nginx安装和使用/">
        
          Nginx安装和使用
        
        <span class="nav-arrow"> →</span>
      </a>
    
  </div>

    <!-- NAV END -->
    <!-- 打赏 START -->
    
    <!-- 打赏 END -->
    <!-- 二维码 START -->
    
    <div class="qrcode">
      <canvas id="share-qrcode"></canvas>
      <p class="notice">扫描二维码，分享此文章</p>
    </div>
    
    <!-- 二维码 END -->
    <!-- Comment -->
    
    <div id="gitalk-container"></div>
    <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css" />

<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

<script type="text/javascript">
  var gitalk = new Gitalk({
    clientID: "87899c539d9076fac82f",
    clientSecret: "86e1b5d21fe5baf128b99ccc6ae72540b89ae1b6",
    repo: "gitalk",
    owner: "linvis",
    admin: "linvis".split(",").filter((l) => l),
    id: decodeURIComponent(location.pathname),
    labels: "gitalk".split(",").filter((l) => l),
    perPage: parseInt("15"),
    pagerDirection: "last",
  });

  gitalk.render("gitalk-container");
</script>
 
  </article>
  <!-- Article END -->
  <!-- Catalog START -->
   <aside class="catalog-container">
  <div class="toc-main">
    <strong class="toc-title">Catalog</strong>
    
      <ol class="toc-nav"><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#Continuous-Bag-of-Word-Model-CBOW"><span class="toc-nav-text">Continuous Bag-of-Word Model(CBOW)</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#One-word"><span class="toc-nav-text">One word</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Forward-propagation"><span class="toc-nav-text">Forward propagation</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#backward-propagation"><span class="toc-nav-text">backward propagation</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#for-hidden-output-vector"><span class="toc-nav-text">for hidden-output vector</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#for-input-hidden-vector"><span class="toc-nav-text">for input-hidden vector</span></a></li></ol></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#Multi-word-context"><span class="toc-nav-text">Multi-word context</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#Skip-Gram-Model"><span class="toc-nav-text">Skip-Gram Model</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#forward-propagation"><span class="toc-nav-text">forward propagation</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#backpropagation"><span class="toc-nav-text">backpropagation</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#For-hidden-output-vector"><span class="toc-nav-text">For hidden-output vector</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#For-input-hidden-vector"><span class="toc-nav-text">For input-hidden vector</span></a></li></ol></li></ol></li></ol>
    
  </div>
</aside> 
  <!-- Catalog END -->
</main>

<script>
  (function () {
    var url = "https://linvis.github.io/2019/07/31/word2vec-paper-reading/";
    var banner = "";
    if (banner !== "" && banner !== "undefined" && banner !== "null") {
      $("#article-banner").css({
        "background-image": "url(" + banner + ")",
      });
    } else {
      $("#article-banner").geopattern(url);
    }
    $(".header").removeClass("fixed-header");

    // error image
    $(".markdown-content img").on("error", function () {
      $(this).attr("src", "http://file.muyutech.com/error-img.png");
      $(this).css({
        cursor: "default",
      });
    });

    // zoom image
    $(".markdown-content img").on("click", function () {
      var src = $(this).attr("src");
      if (src !== "http://file.muyutech.com/error-img.png") {
        var imageW = $(this).width();
        var imageH = $(this).height();

        var zoom = (($(window).width() * 0.95) / imageW).toFixed(2);
        zoom = zoom < 1 ? 1 : zoom;
        zoom = zoom > 2 ? 2 : zoom;
        var transY = (($(window).height() - imageH) / 2).toFixed(2);

        $("body").append(
          '<div class="image-view-wrap"><div class="image-view-inner"><img src="' +
            src +
            '" /></div></div>'
        );
        $(".image-view-wrap").addClass("wrap-active");
        $(".image-view-wrap img").css({
          width: `${imageW}`,
          transform: `translate3d(0, ${transY}px, 0) scale3d(${zoom}, ${zoom}, 1)`,
        });
        $("html").css("overflow", "hidden");

        $(".image-view-wrap").on("click", function () {
          $(this).remove();
          $("html").attr("style", "");
        });
      }
    });
  })();
</script>


<script>
  var qr = new QRious({
    element: document.getElementById("share-qrcode"),
    value: document.location.href,
  });
</script>
  

    <div class="scroll-top">
  <span class="arrow-icon"></span>
</div>
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<footer class="app-footer">
  <p class="copyright">
    &copy; 2020 | Proudly powered by <a href="https://hexo.io" target="_blank">Hexo</a>
    <br>
    Theme by <a href="https://github.com/yanm1ng">yanm1ng</a>
    <br>
    访问量<span id="busuanzi_value_site_pv"></span>,
    访客数<span id="busuanzi_value_site_uv"></span>
  </p>
</footer>

<script>
  function async(u, c) {
    var d = document, t = 'script',
      o = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
    o.src = u;
    if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
    s.parentNode.insertBefore(o, s);
  }
</script>
<script>
  async("//cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.min.js", function(){
    FastClick.attach(document.body);
  })
</script>

<script>
  var hasLine = 'true';
  async("//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js", function(){
    $('figure pre').each(function(i, block) {
      var figure = $(this).parents('figure');
      if (hasLine === 'false') {
        figure.find('.gutter').hide();
      }
      var lang = figure.attr('class').split(' ')[1] || 'code';
      var codeHtml = $(this).html();
      var codeTag = document.createElement('code');
      codeTag.className = lang;
      codeTag.innerHTML = codeHtml;
      $(this).attr('class', '').empty().html(codeTag);
      figure.attr('data-lang', lang.toUpperCase());
      hljs.highlightBlock(block);
    });
  })
</script>
<!-- Baidu Tongji -->

<script src="/js/script.js"></script>
  </body>
</html>